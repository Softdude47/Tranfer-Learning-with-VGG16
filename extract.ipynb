{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"[INFO]: loading Libraries\")\n", "from tensorflow.keras.applications import VGG16\n", "from sklearn.preprocessing import LabelEncoder\n", "from imutils.paths import list_images\n", "from os.path import sep as separator\n", "from random import shuffle"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from datasets.simple_dataset_loader import Simple_Dataset_Loader\n", "from preprocessors.image_to_array import Image_to_Array\n", "from preprocessors.imagenet import Imagenet\n", "from cacher.file_cacher import File_Database"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import argparse"]}, {"cell_type": "markdown", "metadata": {}, "source": ["commandline parameters"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["ap = argparse.ArgumentParser()\n", "ap.add_argument(\"--input_path\", \"-ip\", help=\"path to dataset\", type=str, required=True)\n", "ap.add_argument(\"--output_path\", \"-op\", help=\"path to dataset\", type=str, required=True)\n", "ap.add_argument(\"--show_info\", \"-show\", help=\"show info on extraction process\", type=bool, default=True)\n", "ap.add_argument(\"--image_dimension\", \"-dim\", help=\"target dimension of each images in the dataset\\nfor example (480, 640)\", type=tuple, default=(224,224))\n", "ap.add_argument(\"--batch_size\", \"-bs\", help=\"batch size\", type=int, default=32)\n", "ap.add_argument(\"--buffer_size\", \"-bf\", help=\"buffer size\", type=int, default=1000)\n", "args = vars(ap.parse_args())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["bs = args[\"bs\"]\n", "buffer_size = args[\"bf\"]\n", "input_path = args[\"ip\"]\n", "output_path = args[\"op\"]\n", "target_size = args[\"dim\"]\n", "show_info = args[\"show\"]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["setup image dimension"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["image_paths = list(list_images(input_path))\n", "dimension = [len(image_paths),]\n", "dimension.extend(target_size)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"[INFO]: initializing Key functions\")\n", "# initialize the feature extractor(VGG16) model\n", "feature_extractor = VGG16(include_top=False, weights=\"imagenets\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["initialize and create list of preprocessors"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["IAp = Image_to_Array()\n", "Ip = Imagenet()\n", "preprocessors = [IAp, Ip]\n", "sdl = Simple_Dataset_Loader(preprocessors=preprocessors)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["initialize database"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"[INFO]: creating Database\")\n", "db = File_Database(output_path=output_path, buffSize=buffer_size, dimension=dimension)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["extract image labels(from image paths) and fit it into encoder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["class_names = [i.split(separator)[-2] for i in image_paths]\n", "le = LabelEncoder().fit(class_names)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["store string format of image labels(from image paths) to database"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["db.store_class_labels(le.classes_)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["loop over image paths in batches"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"[INFO]: extracting feature\")\n", "for i in range(0, dimension[0], bs):\n", "    # load images and extract their labels\n", "    batchPath = image_paths[i : i + bs]\n", "    batchImages, batchLabels = sdl.preprocess(batchPath, target_size=target_size, include_label=True)\n", "    \n", "    # encode label and extract feautres\n", "    batchLabels = le.transform(batchLabels)\n", "    batchImages = feature_extractor.predict(batchImages)\n", "    \n", "    # adds extracted features and encodd labels to database\n", "    db.add(batchImages, batchLabels)\n", "    if show_info:\n", "        print(f\"[INFO]: process {i}/{dimension}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["close database"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["db.close()\n", "print(\"[INFO]: success....\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}